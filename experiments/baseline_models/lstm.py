# pytype: skip-file
"""
This module defines continuous LSTM models with ODE or flow-based state
evolution. It includes base classes and specific implementations for ODE-LSTM,
ResNet flow, and coupling flow models.
"""
# Ref: [Neural Flows: Efficient Alternative to Neural ODEs]
# (https://github.com/mbilos/neural-flows-experiments)
from typing import Optional, Tuple

import torch
import torch.nn as nn
from torch import Tensor
from torch.nn import Module

from .flow import CouplingFlow, ResNetFlow
from .ode import ODEModel


class BaseContinuousLSTM(Module):
  """
    Base continuous LSTM class
    Other classes inherit and define `odeint` function

    Args:
        dim: Data dimension
        hidden_dim: Hidden state of LSTM
        odeint: Generic IVP solver, ODE or flow-based model
    """

  def __init__(self, dim: int, hidden_dim: int, odeint: Module):
    super().__init__()
    self.lstm = nn.LSTMCell(dim, hidden_dim)
    self.odeint = odeint

  def forward(
      self,
      x: Tensor,  # Input data
      c: Tensor,  # Previous `c` cell
      h: Tensor,  # Previous `h` cell
      t: Tensor,  # Input time
  ) -> Tuple[Tensor, Tensor,
             Tensor]:  # Pre-jump state `h`, cell `c`, post-jump state `h`

    # Evolve the hidden state in continuous time
    h_pre = self.odeint(h.unsqueeze(1), t.unsqueeze(1)).squeeze(1)

    # Update the hidden state
    c, h = self.lstm(x, (c, h))

    return h_pre, c, h


class ODELSTM(BaseContinuousLSTM):
  """
    ODE-LSTM model

    Args:
        dim: Data dimension
        hidden_dim: LSTM hidden dimension
        activation: Name of the activation function from `torch.nn`
        final_activation: Name of the activation function from `torch.nn`
        solver: Which numerical solver to use (e.g. `dopri5`, `euler`, `rk4`)
        solver_step: How many solvers steps to take, only applicable for fixed
          step solvers
    """

  def __init__(self, dim: int, hidden_dim: int, activation: str, # pylint: disable=unused-argument
               final_activation: str, solver: str, solver_step: int, **kwargs): # pylint: disable=unused-argument
    super().__init__(
        dim,
        hidden_dim,
        ODEModel(
            dim=hidden_dim,
            net="concat",
            hidden_dims=[hidden_dim],
            activation=activation,
            final_activation=final_activation,
            solver=solver,
            solver_step=solver_step,
        ),
    )


class LSTMResNet(BaseContinuousLSTM):
  """
    LSTM-based ResNet flow

    Args:
        dim: Data dimension
        hidden_dim: LSTM hidden dimension
        n_layers: How many flow layers
        time_net: Time embedding module
        time_hidden_dim: Time embedding hidden dimension
    """

  def __init__(self,
               dim: int,
               hidden_dim: int,
               n_layers: int,
               time_net: str,
               time_hidden_dim: Optional[int] = None,
               **kwargs): # pylint: disable=unused-argument
    super().__init__(
        dim,
        hidden_dim,
        ResNetFlow(
            dim=dim,
            n_layers=n_layers,
            hidden_dims=[hidden_dim],
            time_net=time_net,
            time_hidden_dim=time_hidden_dim,
        ),
    )


class LSTMCoupling(BaseContinuousLSTM):
  """
    LSTM-based coupling flow

    Args:
        dim: Data dimension
        hidden_dim: LSTM hidden dimension
        n_layers: How many flow layers
        time_net: Time embedding module
        time_hidden_dim: Time embedding hidden dimension
    """

  def __init__(self,
               dim: int,
               hidden_dim: int,
               n_layers: int,
               time_net: str,
               time_hidden_dim: Optional[int] = None,
               **kwargs): # pylint: disable=unused-argument
    super().__init__(
        dim,
        hidden_dim,
        CouplingFlow(
            dim=hidden_dim,
            n_layers=n_layers,
            hidden_dims=[hidden_dim],
            time_net=time_net,
            time_hidden_dim=time_hidden_dim,
        ),
    )


class ContinuousLSTMLayer(Module):
  """
    Continuous LSTM layer with ODE or flow-based state evolution

    Args:
        dim: Data dimension
        hidden_dim: LSTM hidden dimension
        model: Which model to use (`ode` or `flow`)
        flow_model: Which flow model to use (`resnet` or `coupling`)
        activation: Name of the activation function from `torch.nn`
        final_activation: Name of the activation function from `torch.nn`
        solver: Which numerical solver to use
        solver_step: How many solvers steps to take, only applicable for fixed
          step solvers
        hidden_layers: How many flow layers
        time_net: Time embedding module
        time_hidden_dim: Time embedding hidden dimension
    """

  def __init__(self,
               dim: int,
               hidden_dim: int,
               model: str,
               flow_model: Optional[str] = None,
               activation: Optional[str] = None,
               final_activation: Optional[str] = None,
               solver: Optional[str] = None,
               solver_step: Optional[int] = None,
               hidden_layers: Optional[int] = None,
               time_net: Optional[str] = None,
               time_hidden_dim: Optional[int] = None,
               **kwargs):
    super().__init__()

    self.hidden_dim = hidden_dim

    if model == "ode":
      self.lstm = ODELSTM(dim, hidden_dim, activation, final_activation, solver,
                          solver_step)
    elif model == "flow":
      FlowModel = LSTMResNet if flow_model == "resnet" else LSTMCoupling
      self.lstm = FlowModel(dim, hidden_dim, hidden_layers, time_net,
                            time_hidden_dim)

  def forward(
      self,
      x: Tensor,  # Initial conditions, (..., seq_len, dim)
      t: Tensor,  # Times to solve at, (..., seq_len, dim)
  ) -> Tensor:  # Solutions to IVP given x at t, (..., seq_len, dim)

    # Initialize hidden states
    c, h = torch.zeros(x.shape[0], self.hidden_dim * 2).to(x).chunk(2, dim=-1)
    hiddens = torch.zeros(*x.shape[:-1], self.hidden_dim).to(x)

    for i in range(t.shape[1]):
      # Get pre- and post-jump states and cells
      h_pre, c, h = self.lstm(x[:, i], c, h, t[:, i])
      hiddens[:, i] = h_pre

    return hiddens
